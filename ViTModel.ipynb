import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import timm
# Prepare tea leaf disease test dataset
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
import seaborn as sns
import numpy as np
from google.colab import drive

class VisionTransformer(nn.Module):
    def __init__(self, num_classes):
        super(VisionTransformer, self).__init__()
        self.model = timm.create_model('vit_base_patch16_224', pretrained=True)
        self.model.head = nn.Linear(self.model.head.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

# Prepare tea leaf disease dataset
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

drive.mount('/content/drive')
test_dataset = datasets.ImageFolder(root="path to validation dataset", transform=data_transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
save_path = "path to ViT model"

# Initialize model, loss function, and optimizer
model = VisionTransformer(num_classes=len(test_dataset.classes))
model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))
model.to(device)

import matplotlib.pyplot as plt
from PIL import Image
import os


# Function to predict and visualize the class of a single image
def predict_and_visualize(image_path, model, transform, class_names):
    model.eval()
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(image_tensor)
        _, predicted = torch.max(outputs, 1)

    predicted_class = class_names[predicted.item()]

    # Visualize the image and the predicted label
    plt.imshow(image)
    plt.title(f'Predicted: {predicted_class}')
    plt.axis('off')
    plt.savefig('outputViT.png')
    plt.show()
    # Define the class names based on the dataset's subdirectory names

class_names = test_dataset.classes

    # Example usage with an image path
image_path = "path to image"
predict_and_visualize(image_path, model, data_transform, class_names)

import requests
from io import BytesIO
import telegram
import asyncio

import nest_asyncio
nest_asyncio.apply()

TOKEN = "telegram bot token"
CHAT_ID = "telegram bot chat id"

async def send_photo(image_path):
    bot = telegram.Bot(token=TOKEN)
    with open(image_path, 'rb') as photo:
        await bot.send_photo(chat_id=CHAT_ID, photo=photo)

# Function to predict and visualize the class of a single image
def predict_and_visualize(esp32_image_url, model, transform, class_names):
    model.eval()
    response = requests.get(esp32_image_url)

    if response.status_code == 200:
        image = Image.open(BytesIO(response.content)).convert('RGB')
    else:
        print(f"Failed to fetch image. Status code: {response.status_code}")
        return

    image_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(image_tensor)
        _, predicted = torch.max(outputs, 1)

    predicted_class = class_names[predicted.item()]

    # Visualize the image and the predicted label
    plt.imshow(image)
    plt.title(f'Predicted: {predicted_class}')
    plt.axis('off')
    plt.savefig("outputEsp.png")
    plt.show()
    # Define the class names based on the dataset's subdirectory names

class_names = test_dataset.classes


# Example usage with an image URL from ESP32
esp32_image_url = "url to image clicked by esp32"  # Replace with the actual IP address
predict_and_visualize(esp32_image_url, model, data_transform, class_names)
asyncio.get_event_loop().run_until_complete(send_photo("outputEsp.png")
